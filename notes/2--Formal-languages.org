#+Title: Formal languages
#+Subtitle: Principles of Programming Languages
#+Author: Mark Armstrong
#+Date: Fall 2020
#+Description: Definition and tools for building formal languages.
#+Description: Introduction to semantics.
#+Options: toc:nil

* HTML settings                                 :noexport:

** Reveal settings

#+Reveal_root: ./reveal.js
#+Reveal_init_options: width:1600, height:900, controlsLayout:'edges',
#+Reveal_init_options: margin: 0.1, minScale:0.125, maxScale:5,
#+Reveal_init_options: mouseWheel: true
#+Reveal_extra_css: local.css

# #+HTML: <script src="https://cdnjs.cloudflare.com/ajax/libs/headjs/0.96/head.min.js"></script>

* LaTeX settings                                :noexport:

#+LaTeX_header: \usepackage{amsthm}
#+LaTeX_header: \theoremstyle{definition}
#+LaTeX_header: \newtheorem{definition}{Definition}[section]

#+LaTeX_header: \usepackage{unicode-math}
#+LaTeX_header: \usepackage{unicode}

* Setup                                         :noexport:

** Image creation post-processing

We need to prepend the images resulting from ~dot~ code blocks
with a LaTeX attribute to resize them, or else they run off the page.
This named code block for this task is taken from
[[https://orgmode.org/manual/Results-of-Evaluation.html][the Org manual]], augmented to allow for centering.
We should always provide ~*this*~ for the ~data~ argument.
as in ~:post attr_wrap(data=*this*)~,
and also always set ~:exports results :results drawer~.
If we don't put the results in the drawer, they will pile up
as we evaluate the code block.
#+NAME: attr_wrap
#+BEGIN_SRC sh :var data="" :var width="\\\\textwidth" :var center="t" :results output
  echo "#+ATTR_LATEX: :width $width :center $center"
  echo "$data"
#+END_SRC

* Preamble
:PROPERTIES:
:CUSTOM_ID: Preamble
:END:

** Introduction                                :ignore:

This section introduces the mathematical tools
we will use in the discussion of programming languages
as a /formal/ language.

Several small formal languages (not full programming languages)
are used as examples of the use of these tools.

** Table of contents
:PROPERTIES:
:CUSTOM_ID: Table-of-contents
:END:

# The table of contents are added using org-reveal-manual-toc,
# and so must be updated upon changes or added last.
# Note that hidden headings are included, and so must be deleted!

#+HTML: <font size="-1">
#+begin_scriptsize
  - [[Preamble][Preamble]]
    - [[Table of contents][Table of contents]]
    - [[Notable references][Notable references]]
    - [[Version history][Version history]]
      - [[September 23rd][September 23rd]]
      - [[September 21st][September 21st]]
      - [[September 16th][September 16th]]
      - [[Beginning of course][Beginning of course]]
  - [[Formal languages][Formal languages]]
    - [[The usefulness of formal languages][The usefulness of formal languages]]
    - [[Strings][Strings]]
  - [[Describing the /syntax/ of formal languages][Describing the /syntax/ of formal languages]]
    - [[Regular expressions as in formal language theory][Regular expressions as in formal language theory]]
    - [[The language for a regular expression][The language for a regular expression]]
    - [[Additional operators for more expressive regular expressions][Additional operators for more expressive regular expressions]]
    - [[Regular expression examples][Regular expression examples]]
    - [[Grammars as in formal language theory][Grammars as in formal language theory]]
    - [[Notations for grammar productions in formal language theory][Notations for grammar productions in formal language theory]]
    - [[Conventions for grammars][Conventions for grammars]]
    - [[A simple example grammar][A simple example grammar]]
    - [[Exercise – reading grammars][Exercise – reading grammars]]
    - [[Grammars generate or recognise strings][Grammars generate or recognise strings]]
    - [[Parse trees][Parse trees]]
    - [[Example parse tree][Example parse tree]]
    - [[Another example parse tree][Another example parse tree]]
    - [[Exercise: creating parse trees][Exercise: creating parse trees]]
    - [[Backus-Naur form (BNF)][Backus-Naur form (BNF)]]
    - [[BNF details][BNF details]]
    - [[Aside: ALGOL][Aside: ALGOL]]
    - [[Extended Backus-Naur form (EBNF)][Extended Backus-Naur form (EBNF)]]
    - [[EBNF details][EBNF details]]
    - [[Exercise – translating to EBNF][Exercise – translating to EBNF]]
    - [[EBNF's syntactic sugar][EBNF's syntactic sugar]]
    - [[Exercise – a small language C-like language][Exercise – a small language C-like language]]
    - [[Example – EBNF for C++][Example – EBNF for C++]]
  - [[Parsing and executable code][Parsing and executable code]]
    - [[Atomic syntactic units][Atomic syntactic units]]
    - [[Lexemes and tokens][Lexemes and tokens]]
    - [[Parsing][Parsing]]
    - [[The zeroth step – preprocessing][The zeroth step – preprocessing]]
    - [[The first step – lexical analysis][The first step – lexical analysis]]
    - [[The second step – parsing (syntactic analysis)][The second step – parsing (syntactic analysis)]]
    - [[The third step – (static) semantic analysis][The third step – (static) semantic analysis]]
    - [[The fourth step – intermediate code generation][The fourth step – intermediate code generation]]
    - [[Visualising the entire parsing process][Visualising the entire parsing process]]
  - [[Compilation, interpretation, and hybrid appraoches][Compilation, interpretation, and hybrid appraoches]]
    - [[Compilation][Compilation]]
    - [[Interpreters][Interpreters]]
    - [[Hybrid methods][Hybrid methods]]
  - [[Ambiguity][Ambiguity]]
    - [[An example of ambiguity][An example of ambiguity]]
    - [[Removing ambiguity][Removing ambiguity]]
    - [[Parentheses make structure clear][Parentheses make structure clear]]
    - [[Enforcing precedence with a grammar][Enforcing precedence with a grammar]]
    - [[Enforcing associativity with a grammar][Enforcing associativity with a grammar]]
    - [[“Associative” operations][“Associative” operations]]
    - [[Addition is not associative… in some cases][Addition is not associative… in some cases]]
  - [[Abstract and concrete syntax; setting ambiguity aside][Abstract and concrete syntax; setting ambiguity aside]]
    - [[Abstract syntax trees are parse trees.][Abstract syntax trees are parse trees.]]
    - [[We are interested in abstract syntax][We are interested in abstract syntax]]
  - [[The /semantics/ of formal languages][The /semantics/ of formal languages]]
    - [[Semantic domains][Semantic domains]]
    - [[Example – semantics of a language of natural numbers][Example – semantics of a language of natural numbers]]
    - [[Example – semantics of propositional logic][Example – semantics of propositional logic]]
    - [[Example – small-step semantics of propositional logic][Example – small-step semantics of propositional logic]]
#+end_scriptsize
#+HTML: </font>

** Notable references
:PROPERTIES:
:CUSTOM_ID: Notable-references
:END:

- Benjamin Pierce,
  “[[https://ebookcentral.proquest.com/lib/mcmu/detail.action?docID=3338823][Types and Programming Languages]]”
  - Chapter 3, Untyped Arithmetic Expressions
    - Grammars. Alternative syntactic descriptions. Semantics.
  - Chapter 5, The Untyped Lambda-Calculus
    - Abstract syntax.

- Peter Van Roy and Seif Haridi,
  “[[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.7366&rep=rep1&type=pdf][Concepts, Techniques, and Models of Computer Programming]]”
  - Section 2.1, Defining practical programming languages
    - Grammars. Alternative semantic approach (the kernel approach.)

- Maribel Fernández,
  “[[https://discovery.mcmaster.ca/iii/encore/record/C__Rb2200622?lang=eng][Programming Languages and Operational Semantics: A Concise Overview]]” 
  - Section 1.3, Components of a Programming Language

- Robert W. Sebesta, “Concepts of Programming Languages” (10th edition)
  - Chapter 3, Describing Syntax and Semantics
  - Chapter 4, Lexical and Syntax Analysis

** Version history
:PROPERTIES:
:CUSTOM_ID: Version-history
:END:

*** September 23rd
:PROPERTIES:
:CUSTOM_ID: September-23rd
:END:

Notes completed.

*** September 21st
:PROPERTIES:
:CUSTOM_ID: September-21st
:END:

More complete version posting. Nearly complete up to
Ambiguity.

*** September 16th
:PROPERTIES:
:CUSTOM_ID: September-16th
:END:

More complete version posted. Nearly complete up to Parsing.

After lecture, several typos fixed.
First parse tree example also fixed
(the nodes were in the wrong order.)

*** Beginning of course
:PROPERTIES:
:CUSTOM_ID: Beginning-of-course
:END:

Very incomplete version of the notes in place.

* Formal languages
:PROPERTIES:
:CUSTOM_ID: Formal-languages
:END:

** Preamble                                    :ignore:

Recall, from formal language theory:

A language over an /alphabet/ (set of symbols) $Σ$
is a subset of $Σ^{*}$.
The elements of a language are called /sentences/
(or /strings/ or sometimes /words/).

A /formal/ language is one for which we have a mathematical tool
for either
- /generating/ (or /deriving/) all sentences of the language,
  or equivalently,
- /recognising/ (or /accepting/) only sentences of the language.

Examples of such mathematical tools include
- regular expressions,
- automata, and
- grammars.

** The usefulness of formal languages
:PROPERTIES:
:CUSTOM_ID: The-usefulness-of-formal-languages
:END:

Formal languages, unlike /natural/ languages, are well-suited
for comprehension by computers.
- Machines require unambiguous steps to follow.
- Hence, all programming languages are formal languages.

In particular, in most cases:
- The sets of keywords, names, etc., form several /regular languages/,
  and so can be recognised by regular expressions.
- The set of valid (in terms of form) programs forms
  a /context-free/ language, and so can be recognised by
  a (context-free) grammar.

** Strings
:PROPERTIES:
:CUSTOM_ID: Strings
:END:

Recall that given a set $Σ$, the set of strings over $Σ$,
written $Σ^{*}$, is the set of all finite sequences
of elements of $Σ$.

In particular, the sequence of length zero we denote by $ε$.
Note that some other sources use $λ$ for this purpose.

For example, for $Σ = \{a, b, c\}$,
#+begin_center
$Σ^{*} = \{ε, a, b, c, aa, ab, ac, ba, bb, bc, ca, cb, cc, aaa, …\}$.
#+end_center

Given an element $e ∈ Σ$, we write
- $e^{n}$ for the string consisting of $n$ occurrences of $e$, and
- $e^{*}$ for the set $\{ n ∈ ℕ ∣ e^{n} \}$.

* Describing the /syntax/ of formal languages
:PROPERTIES:
:CUSTOM_ID: Describing-the-/syntax/-of-formal-languages
:END:

** Preamble                                    :ignore:

In this section, we will
- briefly review regular expressions and grammars as
  they are presented in formal language theory, and then
- introduce more practical syntax for each
  which is used in practice.

In both cases, the additional syntax only adds to
the /practical expressiveness/ of the tool.
- It does not change the tool's /theoretical expressiveness/.
  - The same set of languages can be described,
    but many languages can be described “more easily”.
- We will present brief arguments to this effect
  by showing how to translate from the new syntax
  to the restricted syntax.

** Regular expressions as in formal language theory
:PROPERTIES:
:CUSTOM_ID: Regular-expressions-as-in-formal-language-theory
:END:

Given a finite alphabet $Σ$,
the set of regular expressions (over $Σ$),
denoted $RE(Σ)$, is given
by the following rules.
1. $∅$, $ε$ and $a$ (for each $a ∈ Σ$) are regular expressions.
2. $(α | β)$, $(αβ)$ and $(α^{*})$ are regular expressions
   - for any regular expressions α and β.

Respectively, the three operations in (2) are called
- “or”,
- “append”, and
- “star” or “repeat”.  

** The language for a regular expression
:PROPERTIES:
:CUSTOM_ID: The-language-for-a-regular-expression
:END:

The language generated/recognised by a regular expression
is defined via a (semantic) function $L : RE(Σ) → Σ^{*}$,
defined as follows.
- $L(∅) = ∅$
- $L(ε) = \{ ε \}$
- $L(a) = \{ a \}$
- $L(α | β) = L(α) ∪ L(β)$
- $L(αβ) = \{ uv | u ∈ L(α) ∧ v ∈ L(β) \}$
- $L(α^*) = (L(α))^*$

** Additional operators for more expressive regular expressions
:PROPERTIES:
:CUSTOM_ID: Additional-operators-for-more-expressive-regular-expressions
:END:

Regular expressions come up frequently in programming,
and there is a rich set of extensions
to make them easier to construct.

We will not try to extensively list them, but some are listed below,
along with their equivalent “basic” form or,
where that is infeasible to write,
its language.
1. $α^{+} \ \ \ ≈ \ \ \ αα^{*}$
2. $α? \ \ \ ≈ \ \ \ α | ε$
3. $\text{.} \ \ \ ≈ \ \ \ a | b | c | …$ where $Σ = {a, b, c, …}$; i.e., $L(.) = Σ$
4. $[c_{1}…c_{n}] \ \ \ ≈ \ \ \ c_{1} | … | c_{n}$, where each $c_{i}$ is a character.
5. $[\verb!^!c_{1}…c_{n}]$, where $L([\verb!^!c_{1}…c_{n}]) = Σ - [c_{1}…c_{n}]$.
6. $α\{m,n\}$, where $L(α\{m,n\}) = ⋃_{i=m}^{n} L(α)^{i}$
      
** Regular expression examples
:PROPERTIES:
:CUSTOM_ID: Regular-expression-examples
:END:

The set of all non-empty strings over the alphabet
can be described by this regular expression.
- Note that if $Σ$ includes whitespace characters,
  this regular expression will allow strings made only of whitespace.
#+begin_src text
.⁺
#+end_src

The set of all non-empty strings which do not include
the letters ~a~, ~b~ or ~c~ can be described by this regular expression.
#+begin_src text
[^abc]⁺
#+end_src

The set ~{na,nana,banana}~ can be described by
#+begin_src text
(bana|na)(na)?
#+end_src

** Grammars as in formal language theory
:PROPERTIES:
:CUSTOM_ID: Grammars-as-in-formal-language-theory
:END:

Formally, a context-free grammar is a 4-tuple
#+begin_center
$⟨N, Σ, P, S⟩$
#+end_center
where
- $N$ is a finite set of /non-terminal/ symbols
  (sometimes called variables),
- $Σ$ is the underlying alphabet,
  also called the /terminals/ of the grammar,
- $N$ and $Σ$ must be distinct,
- $P$ is a set of /productions/ i.e.,
  a binary relation between $N$ and $(N ∪ Σ)^{*}$,
  - In other words, a multi-valued function from
    nonterminals to strings of non-terminals and terminals,
- $S$ is a distinguished element of $N$, called the /starting nonterminal/.

** Notations for grammar productions in formal language theory
:PROPERTIES:
:CUSTOM_ID: Notations-for-grammar-productions-in-formal-language-theory
:END:

Given
#+begin_center
$(A, α) ∈ P$,
#+end_center
we write
#+begin_center
$A ⟶ α$
#+end_center
and read it as
#+begin_center
“$A$ produces $α$” or “$A$ expands to $α$”.
#+end_center

Given a number of
productions
#+begin_center
$(A, α₁) ∈ P$, $(A, α₂) ∈ P$, …, $(A, αₘ) ∈ P$,
#+end_center
we write
#+begin_center
$A ⟶ α₁ | α₂ | … | αₘ$
#+end_center
as a shorthand.

** Conventions for grammars
:PROPERTIES:
:CUSTOM_ID: Conventions-for-grammars
:END:

Writing the 4-tuple each time we produce a grammar is tedious.

For this reason, we adopt the following conventions
in order to allow us to omit the 4-tuple.
1. We write /only/ the list of productions.
2. The set $N$ is taken to be the set of all symbols
   appearing to the left of a list of productions.
   - Note that this requires each nonterminal have
     at least one production.
3. The set $Σ$ is usually understood by the context
   in which we are defining the grammer.
   - For our purposes, it will usually be the set of
     all ASCII symbols.
4. The starting nonterminal $S$ is understood to be either
   1. the nonterminal whose name matches that of the grammar
      we are defining (it may be uncapitalised or abbreviated),
   2. otherwise, the non-terminal named $S$, or
   3. otherwise, the nonterminal to the left of
      the first production in the list.
      - (We usually attempt to write grammars “top down”.)
      
** A simple example grammar
:PROPERTIES:
:CUSTOM_ID: A-simple-example-grammar
:END:

#+begin_src text
A ⟶ aAa | B
B ⟶ bBb | C
C ⟶ cCc | ε
#+end_src

This produces the language of strings of
the form
#+begin_center
$a^{i}b^{j}c^{k}c^{k}b^{j}a^{i}$
#+end_center

** Exercise – reading grammars
:PROPERTIES:
:CUSTOM_ID: Exercise-–-reading-grammars
:END:

What languages do the following grammars produce?

#+begin_src text
A ⟶ B | C
B ⟶ aaB | ε
C ⟶ aaaC | ε
#+end_src

#+begin_src text
A ⟶ aB | B | ε
B ⟶ bC | C
C ⟶ cA | A
#+end_src

#+begin_src text
A ⟶ aA | B
B ⟶ bB
#+end_src

*What's the tricky part with the last one?*

Extra exercise: can you simplify any of them?
For instance, by having less non-terminals or less productions?
If you believe so, just be careful that
your simplification accepts the same string!

** Grammars generate or recognise strings
:PROPERTIES:
:CUSTOM_ID: Grammars-generate-or-recognise-strings
:END:

We have discussed the facts that a grammar can
- generate strings or
- recognise/accept strings.

Then for a grammar $G$ we might think of functions
- $generateᴳ : ℕ → Σ^{*}$
  - with the intention that $generateᴳ(n)$ generates the $n^{th}$
    string in the grammar's language is lexicographic order
- $recogniseᴳ : Σ^{*} → Bool$
That is, we have two functions, which output a ~String~ or
a ~Bool~ respectively.

But there is a useful byproduct which may be obtained during
during either process: a /parse tree/.

** Parse trees
:PROPERTIES:
:CUSTOM_ID: Parse-trees
:END:

A parse tree's
- nodes (which have children) are
  labelled by a nonterminal of the grammar,
- leaves (which do not have children) are
  labelled by a terminal of the grammar, and
- if a node is labelled by a nonterminal ~A~,
  the children of that node must correspond to
  (in order from left to right)
  the terminals and nonterminals appearing in a production of ~A~.
  If a non-terminal would produce ~ε~, it is omitted.

** Example parse tree
:PROPERTIES:
:CUSTOM_ID: Example-parse-tree
:END:

For example, consider the grammar
#+begin_src text
S ⟶ AB
A ⟶ aA | ε
B ⟶ Bb | b
#+end_src

We have the following parse tree for the string ~aab~.
- Note the dashed portions, which show part of how the tree
  was derived from the grammar,
  but which will usually be omitted by our rules for parse trees.
#+begin_src dot :file media/parse-tree-example-aab.png
digraph T {
  S  [label="S"]
  A1 [label="A"]
  A2 [label="A"]
  A3 [label="A", style=dashed]
  B  [label="B"]

  a1 [label="a", shape=plaintext]
  a2 [label="a", shape=plaintext]
  b  [label="b", shape=plaintext]
  eps [label="ε", style=dashed]
  
  S -> A1 -> a1
  { rank=same; a1 -> A2 [style=invis] }
       A1 -> A2 -> a2
  { rank=same; a2 -> A3 [style=invis] }
       A2 -> A3 [style=dashed]
       A3 -> eps [style=dashed]
  
  S -> B  -> b
}
#+end_src

#+RESULTS:
[[file:media/parse-tree-example-aab.png]]

** Another example parse tree
:PROPERTIES:
:CUSTOM_ID: Another-example-parse-tree
:END:

Similarly, working with the same grammar,
we have the following parse tree for ~abb~.
#+begin_src dot :file media/parse-tree-example-abb.png
digraph T {
  S  [label="S"]
  A  [label="A"]
  B1 [label="B"]
  B2 [label="B"]

  a  [label="a", shape=plaintext]
  b1 [label="b", shape=plaintext]
  b2 [label="b", shape=plaintext]

  S -> A  -> a
  S -> B1 -> b1
       B1 -> B2 -> b2
}
#+end_src

#+RESULTS:
[[file:media/parse-tree-example-abb.png]]

** Exercise: creating parse trees
:PROPERTIES:
:CUSTOM_ID: Exercise:-creating-parse-trees
:END:

Exercise: provide a parse tree for the string ~aaa~ using this grammar.
Is there a valid parse tree for the string ~bbb~?

Exercise: if we add a production ~A ⟶ a~ to our example grammar,
can you provide a different parse tree
(or multiple different parse trees) for ~aaa~?

** Backus-Naur form (BNF)
:PROPERTIES:
:CUSTOM_ID: Backus-Naur-form-(BNF)
:END:

Up until now, we have used the form
#+begin_example text
N₁ ⟶ P₁ | P₂ | …
   ⋮
#+end_example
for our production lists.

Commonly in the study of programming languages,
an alternative syntax called /Backus-Naur/ form (BNF)
is used.
- Named for two members of the ALGOL design committee,
  who created the first formal definition for a programming language,
  namely ALGOL.

** BNF details
:PROPERTIES:
:CUSTOM_ID: BNF-details
:END:

In Backus-Naur form,
- all nonterminals names are delimited by
  angle brackets, ~⟨⟩~,
  - (if using ASCII characters, ~<>~)
- the ~⟶~ is replaced by ~∷=~,
- additional whitespace is permitted on the right side
  of a production between terminals and nonterminals,
  without changing the meaning of the production
  - So $⟨A⟩ ∷= a\ a\ ⟨A⟩$ is treated the same as $⟨A⟩ ∷= aa⟨A⟩$.

** Aside: ALGOL
:PROPERTIES:
:CUSTOM_ID: Aside:-ALGOL
:END:

ALGOL (for “ALGOrithmic Language”)
was a contemporary of Fortran, Lisp, and Cobol.
- Together, those three are the oldest languages
  still in (fairly) common use today.
  - Granted, not the same versions.

Specifically, there were several iterations of ALGOL,
the three major ones being ALGOL 58, ALGOL 60 and ALGOL 68.

ALGOL is not in common use, but it was
the most influential on modern programming language syntax,
introducing concepts such as the block.
- The “C family” can trace its lineage directly to ALGOL.

** Extended Backus-Naur form (EBNF)
:PROPERTIES:
:CUSTOM_ID: Extended-Backus-Naur-form-(EBNF)
:END:

We further extend our grammar notation to include several
several additional operators.
- These extensions are part of the /extended/ Backus-Naur form.
- Once again, this is only an extension in the /practicality/ sense.

There is an [[https://www.iso.org/standard/26153.html][ISO standard]] for EBNF.
Our syntax and inclusion of features is
not chosen to match the standard;
it is what is convenient for our use.

** EBNF details
:PROPERTIES:
:CUSTOM_ID: EBNF-details
:END:

- (Square) brackets, ~[]~, surrounding a string
  indicate that string may or may not be included in a production.
  - I.e., they make part of a production optional.
  - $⟨A⟩ ∷= α₁\ [\ α₂\ ]\ α₃\ \ \ \ ≈ \ \ \ ⟨A⟩ ∷= α₁\ α₂\ α₃\ |\ α₁\ α₃$.
- (Curly) braces, ~{}~, surrounding a string
  indicate that string may be repeated any number of times,
  including zero.
  - $⟨A⟩ ∷= α₁\ \{\ α₂\ \}\ α₃\ \ \ \ ≈ \ \ \ ⟨A⟩ ∷= α₁\ ⟨A′⟩\ α₃$, $⟨A′⟩ ∷= α₂\ ⟨A′⟩\ |\ ε$.
- Parentheses, ~()~, may group parts of a string.
- The “alternative” pipe, ~|~, may be used /inside/ of productions,
  to indicate alternatives inside a set of brackets, braces
  or parentheses.
  - $⟨A⟩ ∷= α₁\ (α₂\ |\ α₃)\ α₄ \ \ \ ≈ \ \ \ ⟨A⟩ ∷= α₁\ α₂\ α₄\ |\ α₁\ α₃\ α₄$.
- Where necessary, terminals may be single or double quoted,
  such as to indicate a whitespace character, pipe or quote.
  - $⟨\text{ebnfprods}⟩ ∷= ⟨\text{string}⟩\ |\ ⟨\text{string}⟩\ ⟨\text{optws}⟩\ “|”\ ⟨\text{optws}⟩\ ⟨\text{ebnfprods}⟩$

** Exercise – translating to EBNF
:PROPERTIES:
:CUSTOM_ID: Exercise-–-translating-to-EBNF
:END:

Translate this grammar from an earlier exercise to EBNF syntax.
#+begin_src text
A ⟶ B | C
B ⟶ aaB | ε
C ⟶ aaaC | ε
#+end_src
Then try to reduce the number of productions in the grammar,
while maintaining the language defined.

Can you use only one production when using EBNF?

** EBNF's syntactic sugar
:PROPERTIES:
:CUSTOM_ID: EBNF's-syntactic-sugar
:END:

EBNF and our extended regular expressions syntax
give us our first example of /syntactic sugar/;
syntax that does not add new features to a language,
only more convenient notation.
- As shown above, any grammar using the additional operators
  can be translated into one not using them.
  - But this likely requires more productions.
  - And certainly more characters/space on the page.
  
Syntactic sugar is a common feature of programming languages.
- Example: (imperative) languages often include various kinds of loops,
  where only one (or sometimes none!) is truly necessary.

When we discuss programming languages formally,
we will usually omit constructs which are syntactic sugar.
- If anything, we may note how to represent them
  in a “core” language which includes less constructs.

** Exercise – a small language C-like language
:PROPERTIES:
:CUSTOM_ID: Exercise-–-a-small-language-C-like-language
:END:

Consider the following context-free language.
#+begin_example text
⟨stmt⟩   ∷= ⟨assign⟩ | ⟨stmt⟩ "; " ⟨stmt⟩
⟨stmt⟩   ∷= "while " ⟨expr⟩ " do " ⟨stmt⟩ | ⟨ws⟩ ⟨stmt⟩ ⟨ws⟩
⟨assign⟩ ∷= ⟨var⟩ ⟨ws⟩ " := " ⟨expr⟩
⟨expr⟩   ∷= ⟨var⟩ | ⟨const⟩ | ⟨expr⟩ ⟨op⟩ ⟨expr⟩ | ⟨ws⟩ ⟨expr⟩ ⟨ws⟩
⟨var⟩    ∷= ('x' | 'y' | 'z') {⟨var⟩}
⟨const⟩  ∷= (1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 0) {⟨const⟩}
⟨op⟩     ∷= '+' | '-' | '*' | '/' | '<' | '>' | '='
⟨ws⟩     ∷= {' '} | {'\n'}
#+end_example

Provide some example programs in this language.

Can you precisely describe the language in English?

** Example – EBNF for C++
:PROPERTIES:
:CUSTOM_ID: Example-–-EBNF-for-C++
:END:

A good example of the practicality EBNF for specifying
the syntax of languages is this
[[http://www.externsoft.ch/download/cpp-iso.html][EBNF grammar for C++]]
(presented in tabular form, rather than lists of productions
as we use).

The grammar is much, much larger than anything we will write,
but it is still quite concise for describing
a real-world programming language.

* Parsing and executable code
:PROPERTIES:
:CUSTOM_ID: Parsing-and-executable-code
:END:

** Preamble                                    :ignore:

We will briefly summarise the parsing process,
beginning with some important terms.
- In this course, we are primarily interested in
  the beginning of this process, up to the
  construction of parse trees.

** Atomic syntactic units
:PROPERTIES:
:CUSTOM_ID: Atomic-syntactic-units
:END:

We have mentioned that both regular expressions and
context-free grammars are used in the description of
the syntax of programming languages.

However, our example programming language earlier
was described exclusively by a context-free grammar.
- Even the smallest syntactic units of the language,
  the /atomic/ syntactic units, have been described by the grammars.
  - For instance, we have used the production
    $⟨const⟩  ∷= (1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 0) \{⟨const⟩\}$
    which describes numerical constants.

This is not done in practice.

** Lexemes and tokens
:PROPERTIES:
:CUSTOM_ID: Lexemes-and-tokens
:END:

In practice,
- regular expressions are instead used to describe the
  atomic syntactic units of languages.
  - For example,
    - keywords such as ~if~ and ~while~, constant values such as ~0~ or ~"abc"~,
      or names such as ~height~ or ~sqrt~.
  - Lexemes cannot be broken down into meaningful pieces.
- Grammars are then used to describe the possible arrangements
  of lexemes.
  - The terminals of the grammar are then names for sets of lexemes,
    called /tokens/, rather than elements of $Σ$.
  - For instance,
    - the token ~while~ for the set containing only the
      keyword ~while~,
    - or the token ~int_literal~ for the set $\{ 0, 1, -1, 2, … \}$,
    - or the token ~var~ for the set of valid variable names.

** Parsing
:PROPERTIES:
:CUSTOM_ID: Parsing
:END:

Parsing is the process of translating a program
from plaintext to executable instructions
- whether this is done
  - ahead of time (compiling) or
  - when the program is to be run (interpreting),
  parsing is a necessary step before execution.
- A computer cannot run unparsed higher level language code.
  
** The zeroth step – preprocessing
:PROPERTIES:
:CUSTOM_ID: The-zeroth-step-–-preprocessing
:END:

Many programming languages support some form
of /preprocessing directives/ which are
to be carried out before the parsing process
properly begins.
- Commonly, “macros”, which often are simply
  textual substitutions to be carried out.
  - But they can be used for significantly more;
    in some instances, these directives
    form a programming language themselves.

** The first step – lexical analysis
:PROPERTIES:
:CUSTOM_ID: The-first-step-–-lexical-analysis
:END:

After preprocessing, if it is present, comes the
the conversion of the plaintext source code
into a sequence of /tokens/.
- This process may be
  called /lexical analysis/, /lexing/ or /tokenising/.
- The program to carry this process out may be
  called a /lexer/ or /tokeniser/.
- Lexical analysis discards whitespace, comments, and any other
  text which is irrelevant to the machine.

** The second step – parsing (syntactic analysis)
:PROPERTIES:
:CUSTOM_ID: The-second-step-–-parsing-(syntactic-analysis)
:END:

After converting from plaintext to a string of tokens, the next
step of parsing is to construct the parse tree.

This step is part of the parsing process,
but it is also usually called parsing.
- It may also be called /syntactic analysis/.

More information about the program may be discarded here,
as the structure of the tree makes certain text
irrelevant (such as parentheses).

** The third step – (static) semantic analysis
:PROPERTIES:
:CUSTOM_ID: The-third-step-–-(static)-semantic-analysis
:END:

Once the parse tree is constructed,
rules about the form of programs
which cannot be (or cannot easily be)
described by a grammar are enforced
by /(static) semantic analysis/.

These rules include type checking and variable scope checking,
issues we will discuss later in the course.

This process produces the /symbol table/, which maps
each identifier to its relevant information,
such as
- where it is declared in the source and
- its type.

** The fourth step – intermediate code generation
:PROPERTIES:
:CUSTOM_ID: The-fourth-step-–-intermediate-code-generation
:END:

Most high-level languages are not translated directly to machine code;
instead, they are translated to some /intermediate code/,
which is closer to machine code than the high-level language.

For instance, languages on the JVM are translated
to Java bytecode during compilation/interpretation.

This intermediate code can then be translated
into machine code by later steps.

** Visualising the entire parsing process
:PROPERTIES:
:CUSTOM_ID: Visualising-the-entire-parsing-process
:END:

#+begin_src ditaa :file media/parsing-whole.png :exports results :results drawer :post attr_wrap(data=*this*)
+-----------+    /--------------\    +--------------------+
| {d}       |    |              |    | {d}                |
| Plaintext +----+ Preprocesser +--->+ Expanded plaintext +-\
| cDDF      |    | cFDD         |    | cDFD               | |
+-----+-----+    \--------------/    +--------------------+ |
                                                            |
             /----------------------------------------------/
             |
/------------+---------------\    +--------------------------+
|                            |    | {d}                      |
|     Lexical analysis       |    |    Sequence of tokens    |
| (constructed from regexps) +--->| (tagged with attributes) +-\
| cFDD                       |    | cDFD                     | |
\----------------------------/    +-----------+--------------+ |
                                                               |
             /-------------------------------------------------/
             |
/------------+---------------\    +----------------------+
|                            |    | {d}                  |
|          Parser            |    |      Parse tree      |
| (constructed from grammar) +--->|                      +-\
| cFDD                       |    | cDFD                 | |
\----------------------------/    +----------------------+ |
                                                           |
              /--------------------------------------------/
              |
/-------------+--------------\    +-------------------------+
|                            |    | {d}                     |
| (Static) semantic analysis |    | Attributed parse tree,  |
|                            +--->|     symbol table        +-\
| cFDD                       |    | cDFD                    | |
\----------------------------/    +-------------------------+ |
                                                              |
              /-----------------------------------------------/
              |
/-------------+---------------\    +-----------------------+
|                             |    | {d}                   |
| Intermediate code generator |    | Intermediate language |
|                             +--->+          code         +-\
|  cFDD                       |    | cDFD                  | |
\-----------------------------/    +-----------------------+ |
                                                             |
         /---------------------------------------------------/
         |
/--------+--------------\    +-----------------+
|                       |    | {d}             |
| Intermediate language |    | Executable code |
|     implemention      |--->|                 |
| cFDD                  |    | cDDF            |
\-----------------------/    +-----------------+
#+end_src

#+RESULTS:
:results:
#+ATTR_LATEX: :width \textwidth :center t
[[file:media/parsing-whole.png]]
:end:

* Compilation, interpretation, and hybrid appraoches
:PROPERTIES:
:CUSTOM_ID: Compilation,-interpretation,-and-hybrid-appraoches
:END:

We have mentioned above during the discussion of parsing
the notions of compilation and interpretation.

Let us define those terms.

** Compilation
:PROPERTIES:
:CUSTOM_ID: Compilation
:END:

A /compiler/ translates the whole program
(and any libraries or other code resources needed)
ahead of running it.
- High upfront cost (time), for increased efficiency at runtime
- Not portable; machine code is machine dependent.
  
** Interpreters
:PROPERTIES:
:CUSTOM_ID: Interpreters
:END:

An /interpreter/ translates the program /as we are running it/.
- No upfront cost, but less efficient.
- Portable; can be run on any machine with an interpreter.
  - Alleviates some of the programmer's responsibility.
    - One user (or group) writes the interpreter /once/
      (per machine type);
      it can be used by any number of users for any number programs.
- Efficiency is improved by using *just-in-time compilation*.
  - Store the result of interpretation so it can be used again.
- Can achieve better error reporting.
  - Relationship between original and translated codes is known at runtime.
  - This relationship is discarded when compiling code.
    
** Hybrid methods
:PROPERTIES:
:CUSTOM_ID: Hybrid-methods
:END:

/Hybrid methods/ compile into a special intermediate language,
which is then interpreted into machine code when the program is run.
- This intermediate language is usually similar to assembly.
  - But targets a virtual machine, not actual hardware!
- Usually called /bytecode/.
- Greatly offsets efficiency cost of interpretation.
- More portable than compiled code; just need
  a bytecode interpreter for each target machine.

* Ambiguity
:PROPERTIES:
:CUSTOM_ID: Ambiguity
:END:

** Preamble                                    :ignore:

We have discussed parse trees as a representation
of programs used during the parsing process.

Parse trees are extremely helpful because they allow us
to discard irrelevant details about program text,
and focus on the form of programs.

However, there is one significant problem which can occur:
what if a program has *multiple* parse trees?

It is desirable to have a single parse tree for every program.
- We should not admit two syntactic interpretations for a program!

This can happen quite frequently, and we must discuss
methods of eliminating such /ambiguity/.

** An example of ambiguity
:PROPERTIES:
:CUSTOM_ID: An-example-of-ambiguity
:END:

For instance, the string ~aa~ has four valid parse trees
under the grammar
#+begin_src text
⟨A⟩ ∷= a ⟨A⟩ | ⟨A⟩ a | ε 
#+end_src

Exercise: find all four valid parse trees for ~aa~ with the above
grammar.

** Removing ambiguity
:PROPERTIES:
:CUSTOM_ID: Removing-ambiguity
:END:

Three tools for removing ambiguity are
- requiring parentheses,
- introducing precedence rules, and
- introducing associativity rules.

The first option takes the least work on the language designer's part.
- But users of a language usually do not appreciate
  “unnecessary” mandatory parenthesisation.

** Parentheses make structure clear
:PROPERTIES:
:CUSTOM_ID: Parentheses-make-structure-clear
:END:

#+begin_quote
#+ATTR_LATEX: :width \textwidth :center t
[[file:./media/comics/language.png]]
#+end_quote
From the SMBC comic “[[http://smbc-comics.com/comic/language][Language]]”

** Enforcing precedence with a grammar
:PROPERTIES:
:CUSTOM_ID: Enforcing-precedence-with-a-grammar
:END:

To enforce precedence using a grammar:
- Create a hierarchy of non-terminals.
- Higher-precedence operators are produced lower in the hierarchy.
- For instance,
  - An additive term can be an addition of multiplicative terms,
    which is a multiplication of atoms, which in turn are
    either a constant, variable or a *parenthesised term*.
  - Note that there is recursion in the above,
    but it's “guarded” with parentheses!

For instance, if we call an additive term simply a ~⟨term⟩~ and
a multiplicative term a ~⟨factor⟩~, we might have a grammar
#+begin_src text
⟨term⟩ ∷= ⟨term⟩ + ⟨term⟩ | ⟨term⟩ - ⟨term⟩ | ⟨factor⟩
⟨factor⟩ ∷= ⟨factor⟩ * ⟨factor⟩ | ⟨factor⟩ / ⟨factor⟩ | ⟨atom⟩
⟨atom⟩ ∷= constant | variable | '(' ⟨term⟩ ')'
#+end_src

** Enforcing associativity with a grammar
:PROPERTIES:
:CUSTOM_ID: Enforcing-associativity-with-a-grammar
:END:

To enforce associativity using a grammar:
- Left associative operators should be produced by left recursive
  non-terminals.
- And right associative operators by right recursive non-terminals.
- Operators of the same precedence must associate the same way!

For instance, to iterate on our previous example grammar,
we might write
#+begin_src text
⟨term⟩ ∷= ⟨factor⟩ + ⟨term⟩ | ⟨term⟩ - ⟨factor⟩ | ⟨factor⟩
⟨factor⟩ ∷= ⟨atom⟩ * ⟨factor⟩ | ⟨factor⟩ / ⟨atom⟩
⟨atom⟩ ∷= constant | variable | '(' ⟨term⟩ ')'
#+end_src
Then ~+~ is right associative, ~-~ is left associative,
and similarly ~*~ is right associative and ~/~ is left associative.

** “Associative” operations
:PROPERTIES:
:CUSTOM_ID: What-about-“associative”-operations?
:END:

You know that in mathematics,
we often avoid parentheses by declaring operations
to be /left associative/ or /right associative/.
- For a left associative operator ~⊕~,
  ~a ⊕ b ⊕ c = (a ⊕ b) ⊕ c~.
  - Examples include subtraction.
- For a right associative operator ~⊕~,
  ~a ⊕ b ⊕ c = a ⊕ (b ⊕ c)~.
  - Examples include exponentiation.
- An /associative/ operator is a ~⊕~ for which
  ~a ⊕ b ⊕ c = (a ⊕ b) ⊕ c = a ⊕ (b ⊕ c)~.

But in computing, some operators behave differently than
their mathematical “selves”.

** Addition is not associative… in some cases
:PROPERTIES:
:CUSTOM_ID: Addition-is-not-associative…-in-some-cases
:END:

Recall that addition is an associative operator.
- So the choice of whether addition in a language associates to
  the right or to the left may seem arbitrary.
- But numerical types in programming are not necessarily
  the same as numerical types in math!
- Addition of floating point numbers /is not associative/.
  - Consider a binary representation with two-digit coefficients.
  - We will suffix the base with a subscript ~b~ to indicate
    these are binary numbers.
  - $1.0_{b} × 2^{0} + 1.0_{b} × 2^{0} + 1.0_{b} × 2^{2}$ has a different value depending
    upon parenthesisation.

#+begin_center
$(1.0_{b} × 2^{0} + 1.0_{b} × 2^{0}) + 1.0_{b} × 2^{2}\ \ =\ \ 1.0_{b} × 2^{1} + 1.0_{b} × 2^{2}\ \ =\ \ 1.1_{b} × 2^{2}$
#+end_center

#+begin_center
$1.0_{b} × 2^{0} + (1.0_{b} × 2^{0} + 1.0_{b} × 2^{2})\ \ =\ \ 1.0_{b} × 2^{0} + 1.0_{b} × 2^{2}\ \ =\ \ 1.0_{b} × 2^{2}$
#+end_center
    
* Abstract and concrete syntax; setting ambiguity aside
:PROPERTIES:
:CUSTOM_ID: Abstract-and-concrete-syntax;-ignoring-ambiguity
:END:

“Simple”, ambiguous grammars do have a place in describing
programming language syntax.
- Such grammars describe the /abstract syntax/ of the language.
  - As opposed to /concrete syntax/.
- Consider programs as /trees/ generated by the grammar
  for the abstract syntax of the language.
  - There may be ambiguity when translating a plaintext program to a tree.
  - But once a tree representation is chosen,
    *there is no ambiguity*!
    - It may be that two different trees “flatten” to the same program,
      but one tree cannot “flatten” to two different programs.
  - Such trees more efficiently represent programs.
    - The shape of the tree expresses structure.
    - Other unnecessary details may be left out.

** Abstract syntax trees are parse trees.
:PROPERTIES:
:CUSTOM_ID: Abstract-syntax-trees-are-parse-trees.
:END:

We have already discussed how /parse trees/ are used
as an internal representation of programs
after parsing.
- We also stated that we discard irrelevant details during
  lexical analysis and parsing (syntactic analysis.)
  - Such as whitespace, comments, and *during parsing*, parentheses!

It is common to give two grammars for a language.
- The concrete grammar describes the written form of programs.
- The abstract grammar describes the internal representation of programs.

For this reason, /parse trees/ are also called /abstract syntax trees/ (ASTs.)

** We are interested in abstract syntax
:PROPERTIES:
:CUSTOM_ID: We-are-interested-in-abstract-syntax
:END:

For the remainder of the course, we will focus on abstract syntax.

In particular, in the discussion of the semantics of formal languages,
concrete syntactic details are not of interest to us.

* The /semantics/ of formal languages
:PROPERTIES:
:CUSTOM_ID: The-/semantics/-of-formal-languages
:END:

** Preamble                                    :ignore:

The /semantics/ of a language assigns a meaning to each sentence.
- In order to define a semantics, we must
  have in mind a /semantic domain/;
  - a domain of meanings into which we map sentences.
- For instance, if we are defining a language
  of natural numbers /Nat/, we will map sentences into the set ~ℕ~.
- Or map elements of a languages of propositions into ~𝔹~.
- We may often provide several different definitions of
  a particular mapping, to emphasise different details.

** Semantic domains
:PROPERTIES:
:CUSTOM_ID: Semantic-domains
:END:

We may also have several semantic domains for a given language.
- In the case of programming languages,
  several domains of meaning have been proposed and used;
  the three most well known are
  - computing devices, whether a real-world machine or an /abstract/ machine,
    - this is known as /operational semantics/
  - (mathematical) functions,
    - this is known as /denotational semantics/
  - precondition/postcondition pairs
    - this is known as /axiomatic semantics/

** Example – semantics of a language of natural numbers
:PROPERTIES:
:CUSTOM_ID: Example-–-semantics-of-a-language-of-natural-numbers
:END:

Consider a language of terms intended to represent
natural numbers.
#+begin_src text
⟨nat⟩ ∷= zero | suc ⟨nat⟩ 
#+end_src

To assign meaning to these terms,
we introduce a mapping from these (concrete) terms
to (abstract) numerals.
#+begin_src text
eval zero = 0
eval (suc n) = (eval n) + 1
#+end_src

The evaluation function in this case is very obvious and trivial,
because this language is simply a concrete representation
of the semantic domain.
- In comparison, when defining the semantics of programming languages,
  the language and the semantic domain are not so directly related.

** Example – semantics of propositional logic
:PROPERTIES:
:CUSTOM_ID: Example-–-semantics-of-propositional-logic
:END:

As a more complex example, we can map propositional logic terms
into the set of booleans.
#+begin_src text
⟨prop⟩ ∷= tt | ff | ¬ ⟨prop⟩ | ⟨prop⟩ (∧ | ∨ | ⇒ | ⇔) ⟨prop⟩
#+end_src

In order to make the mapping less trivial, let us define it
without using boolean combinators; only constants
and “if-then-else” statements.
#+begin_src text
eval tt = true
eval ff = false

eval (¬ p) = false   if eval p
             true    otherwise

eval (p ∧ q) = eval q   if eval p
               false    otherwise

…
#+end_src
Exercise: Complete this evaluation function.

** Example – small-step semantics of propositional logic
:PROPERTIES:
:CUSTOM_ID: Example-–-small-step-semantics-of-propositional-logic
:END:

The evaluation function defined above can be considered
to be a /big-step/ semantics.
- It is a (single-valued) relation between terms and
  their (final) value.

In contrast, we may define a /small-step/ semantics
- which maps terms to terms which are “one step” simpler.
- Then, once we have reduced to a constant term, that may be mapped
  to a value (this part is not shown here).
#+begin_src text
reduce (¬ tt) = ff
reduce (¬ ff) = tt
reduce (¬ p)  = ¬ (reduce p)

reduce (tt ∧ q) = reduce q
reduce (ff ∧ q) = ff
reduce (p ∧ q)  = (reduce p) ∧ q

…
#+end_src
Exercise: Complete this reduction function.
